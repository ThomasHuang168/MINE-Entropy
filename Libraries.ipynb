{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DiscreteRV_MutualInfo(rv):#def MutualInfo(rv):\n",
    "    numRV = rv.shape[0]\n",
    "    RVsize = rv.shape[1]\n",
    "    histRV = np.array(np.unique(rv[0], axis=0, return_counts=True)[1])[None,:]\n",
    "    histRV2 = np.array(np.unique(rv[(0,1),:], axis=1, return_counts=True)[1])[None,:]\n",
    "    for i in range(1, numRV):\n",
    "        histRV = np.append(histRV, np.array(np.unique(rv[i], axis=0, return_counts=True)[1])[None,:], axis=0)\n",
    "        if i!=1:\n",
    "            for j in range(i):\n",
    "                newArr = np.unique(rv[(j,i),:], axis=1, return_counts=True)\n",
    "                histRV2 = np.append(histRV2, np.array(newArr[1])[None,:], axis=0)\n",
    "    pmfRV = histRV/RVsize\n",
    "    pmfRV2 = histRV2/RVsize\n",
    "    H = -1*np.average(np.log(pmfRV), weights=pmfRV, axis=1)\n",
    "    H2 = -1*np.average(np.log(pmfRV2), weights=pmfRV2, axis=1)\n",
    "    MI = np.zeros(H2.shape)\n",
    "    index = 0\n",
    "    for i in range(1, numRV):\n",
    "        for j in range(i):\n",
    "            MI[index] = H2[index] - H[i] - H[j]\n",
    "            index = index + 1\n",
    "    return MI\n",
    "\n",
    "def DiscreteEntropy(y):\n",
    "    #cols = y.shape[y.ndim-1]\n",
    "    #rows = y.shape[0]\n",
    "    pmf = np.unique(y, return_counts=True, axis=y.ndim-1)[1]/y.shape[y.ndim-1]\n",
    "    return -1*np.average(np.log(pmf), weights=pmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import comb\n",
    "def subset(size, index):\n",
    "    subset = [-1]\n",
    "    sum = 0\n",
    "    for numOutput in range(size + 1):\n",
    "        c = comb(size, numOutput)\n",
    "        if index >= sum + c:\n",
    "            sum += c\n",
    "        else:\n",
    "            break\n",
    "    #print (numOutput)\n",
    "    numLeft = numOutput\n",
    "    for candidate in range(size-1, -1, -1):\n",
    "        if index == sum:\n",
    "            for remaining in range(numLeft-1, -1, -1):\n",
    "                if subset[0] == -1:\n",
    "                    subset[0] = remaining\n",
    "                else:\n",
    "                    subset = np.append(subset, remaining)\n",
    "            break\n",
    "        elif 0 == numLeft:\n",
    "            break\n",
    "        elif (index - sum) >= comb(candidate, numLeft):\n",
    "            sum += comb(candidate, numLeft)\n",
    "            if subset[0] == -1:\n",
    "                subset[0] = candidate\n",
    "            else:\n",
    "                subset = np.append(subset, candidate)\n",
    "            numLeft -= 1\n",
    "    #print(output)\n",
    "    if subset[0] != -1:\n",
    "        return subset\n",
    "\n",
    "def subsetIndex(size, subset):\n",
    "    index = 0\n",
    "    if np.all(subset) != None:\n",
    "        subset = np.array(subset)\n",
    "        numSubset = subset.size\n",
    "        for i in range(numSubset):\n",
    "            index += comb(size, i)\n",
    "        sorted = np.sort(subset)\n",
    "        for i in range(numSubset - 1, -1, -1):\n",
    "            if sorted[i] > i:\n",
    "                index += comb(sorted[i], i + 1)\n",
    "    return index\n",
    "            \n",
    "def TestSubsetAndIndex(size):\n",
    "    pow = 2**size\n",
    "    print (\"Test Subset with size=\", size, \" and pow=\", pow)\n",
    "    for i in range(pow):\n",
    "        set = subset(size, i)\n",
    "        print(i, \"\\t\", subsetIndex(size, set), \"\\t\", set)\n",
    "\n",
    "def ConditionSet(size, Resp, index):\n",
    "    set = subset(size - 1, index)\n",
    "    cond = [-1]\n",
    "    for element in set:\n",
    "        if element >= Resp:\n",
    "            element += 1\n",
    "        if cond[0] == -1:\n",
    "            cond[0] = element\n",
    "        else:\n",
    "            cond = np.append(cond, element)\n",
    "    return cond\n",
    "\n",
    "def ConditionIndex(size, Resp, cond):\n",
    "    if (np.ma.is_masked(cond)):\n",
    "        condSet = []\n",
    "        for i in range(cond.size):\n",
    "            if cond.mask[i] == False:\n",
    "                if cond[i] > Resp:\n",
    "                    condSet.append(cond[i] - 1)\n",
    "                else:\n",
    "                    condSet.append(cond[i])\n",
    "        condSet = np.array(condSet)\n",
    "        sizeUnmasked = size - np.ma.count_masked(cond)\n",
    "        indexInResp = subsetIndex(sizeUnmasked, condSet)\n",
    "    else:\n",
    "        condSet = np.zeros(cond.shape)\n",
    "        for i in range(condSet.size):\n",
    "            if cond[i] > Resp:\n",
    "                condSet[i] = cond[i] - 1\n",
    "            else:\n",
    "                condSet[i] = cond[i]\n",
    "        indexInResp = subsetIndex(size, condSet)\n",
    "    return indexInResp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.special import softmax\n",
    "def NegLogLikeScorer_Softmax(estimator, X, y):\n",
    "    y_est = estimator.predict_proba(X)\n",
    "    y_exp = np.exp(y_est)\n",
    "    y_sum = np.sum(y_exp, axis=1)\n",
    "    sm_est = y_exp/np.broadcast_to(y_sum[:,None],y_exp.shape)\n",
    "    #sm_est = softmax(y_est, axis=1)\n",
    "    y_like, count = np.unique(sm_est[np.arange(y.size), y], return_counts=True)\n",
    "    if 0 == y.size:\n",
    "        return -1\n",
    "    #ignore 0 likelihood\n",
    "    if 0 == y_like[0]:\n",
    "        nom = -1*np.average(np.log(y_like[1:]), weights=count[1:])\n",
    "        if 1 == y.size:\n",
    "            return 0\n",
    "    else:\n",
    "        nom = -1*np.average(np.log(y_like), weights=count)\n",
    "    return nom/y.size\n",
    "\n",
    "def NegLogLikeScorer(estimator, X, y):\n",
    "    y_est = estimator.predict_proba(X)\n",
    "    y_like, count = np.unique(y_est[np.arange(y.size), y], return_counts=True)\n",
    "    if 0 == y.size:\n",
    "        return -1\n",
    "    #ignore 0 likelihood\n",
    "    if 0 == y_like[0]:\n",
    "        nom = -1*np.average(np.log(y_like[1:]), weights=count[1:])\n",
    "        if 1 == y.size:\n",
    "            return 0\n",
    "    else:\n",
    "        nom = -1*np.average(np.log(y_like), weights=count)\n",
    "    return nom/y.size\n",
    "\n",
    "def CondDEntropyScorer(estimator, X, y):\n",
    "    y_est = estimator.predict(X)\n",
    "    #print (np.unique(np.array([y,y_est]), return_counts=True, axis=1))\n",
    "    return DiscreteEntropy(np.array([y,y_est])) - DiscreteEntropy(y_est)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#print (cross_val_score(clf,np.transpose(rv[ConditionSet(numRV, 0, 6)]), rv[0], cv=3, scoring=CondEntropyScorer))\n",
    "\n",
    "\n",
    "def computeEnt(rv, clf, scorer, entropy, CV_Fold, verbose=False):\n",
    "    num_RV = rv.shape[0]\n",
    "    _high = np.amax(rv)\n",
    "    _low = np.amin(rv)\n",
    "    numComb = np.power(2, num_RV - 1)\n",
    "    DEntropy = np.zeros((num_RV, numComb))\n",
    "    if verbose:\n",
    "        print (num_RV, \" Discrete RVs with range [\", _low, \", \", _high, \"]\")\n",
    "        print (\"Resp\\tCond\\tH(Resp|Cond)\")\n",
    "    for Resp in range(num_RV):\n",
    "        DEntropy[Resp,0] = entropy(rv[Resp])\n",
    "        for sI in range(1, numComb):\n",
    "            DEntropy[Resp,sI] = np.mean(cross_val_score(clf,np.transpose(rv[ConditionSet(num_RV, Resp, sI)]), rv[Resp], cv=CV_Fold, scoring=scorer))\n",
    "            if verbose:\n",
    "                print (Resp, \"\\t\", ConditionSet(num_RV, Resp, sI), \"\\t\", DEntropy[Resp,sI])\n",
    "    return DEntropy\n",
    "\n",
    "def getRandomVar_select(method, low, high, RVsize, numRV, depend):\n",
    "    rv = np.split(method(low, high, size=RVsize*(numRV - 1)), numRV - 1)\n",
    "    rv_sel = np.array(rv)[depend]\n",
    "    rv = np.append(rv, np.remainder(np.sum(rv_sel, axis=0), high)[None,:], axis=0)\n",
    "    print (rv)\n",
    "    return rv\n",
    "\n",
    "def getRandomVar(method, low, high, RVsize, numRV):\n",
    "    rv = np.split(method(low, high, size=RVsize*(numRV - 1)), numRV - 1)\n",
    "    rv = np.append(rv, np.remainder(np.sum(rv, axis=0), high)[None,:], axis=0)\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMI(MI, index, depth=0, printAtDepth = 0):\n",
    "    setSize = index.size - np.ma.count_masked(index)\n",
    "    MI_set = 0\n",
    "    k = 0\n",
    "    if (setSize > 1):\n",
    "        if (depth == printAtDepth):\n",
    "            print (\"MI[{0}] = 1/{1}*E(\".format(index, setSize -1))\n",
    "        for i in range(index.size):\n",
    "            if (index.mask[i] == False):\n",
    "                index.mask[i] = True\n",
    "                ci = ConditionIndex(MI.shape[0], i, index) - 1\n",
    "                MI_set += MI[i,int(ci)]\n",
    "                if (depth == printAtDepth):\n",
    "                    print(\"MI[{0},{1}] \".format(i,index), end = '')\n",
    "                if (np.ma.count_masked(index) < index.size):\n",
    "                    j_next = depth + 1\n",
    "                    subMI = MMI(MI, index, j_next, printAtDepth)\n",
    "                    MI_set += subMI*(setSize - 2)\n",
    "                    if (depth == printAtDepth):\n",
    "                        print(\"+ {0}*MI[{1}]\".format(setSize-2, index), end='')\n",
    "                index.mask[i] = False\n",
    "                k += 1\n",
    "                if (k < setSize):\n",
    "                    if (depth == printAtDepth):\n",
    "                        print(\" , \")\n",
    "                else:\n",
    "                    if (depth == printAtDepth):\n",
    "                        print(\"\")\n",
    "                    break\n",
    "        MI_set /= (setSize - 1)\n",
    "        MI_set /= setSize\n",
    "        if (depth == printAtDepth):\n",
    "            print (\") = {0}\".format(MI_set))\n",
    "    return MI_set\n",
    "\n",
    "def CondEnt2MMI(MMI, CondEnt):\n",
    "    MI = np.broadcast_to(CondEnt[:,0][:,None], CondEnt[:,1:].shape) - CondEnt[:,1:]\n",
    "    index = np.ma.array(np.arange(numRV), mask=False)\n",
    "    depth = 0\n",
    "    return MMI(index, depth, MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import gamma,psi\n",
    "from scipy import ndimage\n",
    "from scipy.linalg import det\n",
    "from numpy import pi\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "def Ent_knn(X, k=6):\n",
    "    if 1 == X.ndim:\n",
    "        X = X[:,None]\n",
    "    else:\n",
    "        X = np.transpose(X)\n",
    "    #print(X)\n",
    "    knn = NearestNeighbors(n_neighbors=k)\n",
    "    knn.fit(X)\n",
    "    d, _ = knn.kneighbors(X)\n",
    "    r = d[:,-1]\n",
    "    #print (\"X.ndim={0} r = {1}\".format(X.ndim, d))\n",
    "    n, d = X.shape\n",
    "    volume_unit_ball = (pi**(.5*d)) / gamma(.5*d + 1)\n",
    "    \n",
    "    return (d*np.mean(np.log(r + np.finfo(X.dtype).eps))\n",
    "            + np.log(volume_unit_ball) + psi(n) - psi(k))\n",
    "\n",
    "def MI_knn(X, resp, cond):\n",
    "    return (Ent_knn(X[resp]) + Ent_knn(X[cond]) - Ent_knn(X))\n",
    "\n",
    "def MI_Unsuperwise(X, scorer):\n",
    "    num_RV = X.shape[0]\n",
    "    #print (\"X shape = {0}\".format(num_RV))\n",
    "    numMIperRV = np.power(2, num_RV - 1)\n",
    "    MI = np.zeros((num_RV, numMIperRV-1))\n",
    "    for Resp in range(num_RV):\n",
    "        for sI in range(1, numMIperRV):\n",
    "            MI[Resp, sI-1] = scorer(X, Resp, ConditionSet(num_RV,Resp,sI))\n",
    "    return MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MINE\n",
    "def MI_MINE(X):\n",
    "    num_RV = X.shape[0]\n",
    "    #print (\"X shape = {0}\".format(num_RV))\n",
    "    numMIperRV = np.power(2, num_RV - 1)\n",
    "    MI = np.zeros((num_RV, numMIperRV-1))\n",
    "    \n",
    "    for Resp in range(num_RV):\n",
    "        for sI in range(1, numMIperRV):\n",
    "            #MI[Resp, sI-1] = scorer(X, Resp, ConditionSet(num_RV,Resp,sI))\n",
    "            mine_net = MINE.Mine()\n",
    "            print(ConditionSet(num_RV,Resp,sI))\n",
    "            mine_net_optim = MINE.optim.Adam(mine_net.parameters(), lr=1e-3)\n",
    "            mine_net,tl ,vl = MINE.train(np.transpose(x),mine_net,mine_net_optim, \\\n",
    "                                    resp = Resp, cond = ConditionSet(num_RV,Resp,sI),\\\n",
    "                                    verbose=False, batch_size=100, patience=20)\n",
    "            result_ma = MINE.ma(vl)\n",
    "            MMI[Resp, sI-1] = result_ma[-1]\n",
    "    return MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.67563029 -1.59945382 -0.26244341]\n",
      " [-1.67563029 -1.55699091 -0.2111143 ]\n",
      " [-1.59945382 -1.55699091 -0.1682643 ]]\n",
      "-0.9123161699778707\n",
      "[1]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-739b328d0246>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m#KNN.append(np.mean(MI_knn0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mMI_MINE2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMI_MINE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-bb52981155d0>\u001b[0m in \u001b[0;36mMI_MINE\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     14\u001b[0m             mine_net,tl ,vl = MINE.train(np.transpose(x),mine_net,mine_net_optim, \\\n\u001b[1;32m     15\u001b[0m                                     \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConditionSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_RV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mResp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                                     verbose=False, batch_size=100, patience=20)\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mresult_ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMINE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mMMI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mResp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msI\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/MMI/MINE.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data, mine_net, mine_net_optim, resp, cond, batch_size, iter_num, log_freq, avg_freq, verbose, patience)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m#get train data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mbatchTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mmi_lb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma_et\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn_mine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmine_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmine_net_optim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma_et\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi_lb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/MMI/MINE.py\u001b[0m in \u001b[0;36msample_batch\u001b[0;34m(data, resp, cond, batch_size, sample_mode, randomJointIdx)\u001b[0m\n\u001b[1;32m     97\u001b[0m             batch_mar = np.concatenate([batch_joint[:,resp].reshape(-1,1),\n\u001b[1;32m     98\u001b[0m                                          batch_joint[marginal_index][:,cond].reshape(-1,data.shape[1]-1)],\n\u001b[0;32m---> 99\u001b[0;31m                                        axis=1)\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_joint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #TestSubsetAndIndex(6)\n",
    "    #ground truth\n",
    "\n",
    "    # low, high, RVsize, numRV = 0, 2, 1000, 6\n",
    "    # depend = np.array([0, 1, 2])\n",
    "    # rv = getRandomVar_select(randint.rvs, low, high, RVsize, numRV, depend)\n",
    "\n",
    "    # from sklearn import neighbors\n",
    "    # numNeighbors = high\n",
    "    # clf = neighbors.KNeighborsClassifier(numNeighbors)\n",
    "\n",
    "    # CVFold = 3\n",
    "    # computeEnt(rv, clf, CondDEntropyScorer, DiscreteEntropy, CVFold)\n",
    "\n",
    "#     numRV = 6\n",
    "#     index = np.ma.array(np.arange(numRV), mask=False)\n",
    "#     for i in range(numRV):\n",
    "#         index.mask[i] = True\n",
    "#         print(\"CondIndex[{0},{1}]={2}\".format(i,index,ConditionIndex(numRV, i, index)))\n",
    "#         #print (index.shape)\n",
    "#         index.mask[i] = False\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    linReg = LinearRegression()\n",
    "    CVFold = 3\n",
    "    KNN = []\n",
    "    LinReg2 = []\n",
    "    GT2 = []\n",
    "    #COV2 = []\n",
    "    #for i in range(1, 16):\n",
    "    #    cov = 1 - 0.1**\n",
    "    #    COV2.append(cov)i\n",
    "    COV2 = np.linspace(0, 0.7, 5)\n",
    "    for cov in COV2:\n",
    "        Gaussian_cov3 = [[1,0,cov],[0,1,cov],[cov,cov,1]]\n",
    "        mean3 = [0,0,0]\n",
    "        Gaussian_cov2 = [[1,cov],[cov,1]]\n",
    "        mean2 = [0,0]\n",
    "        x = np.transpose(np.random.multivariate_normal( mean=mean3,\n",
    "                                      cov=Gaussian_cov3,\n",
    "                                     size = 300))\n",
    "#         DE = computeEnt(x, linReg, MSEscorer, varEntropy, CVFold)\n",
    "#         numVar = DE.shape[0]\n",
    "#         MI = DE[1,0] + DE[0,0] - DE[0,1] - DE[1,1]\n",
    "#         MI = MI/3\n",
    "#         LinReg2.append(MI)\n",
    "\n",
    "        #groundTruth = -0.5*np.log(1-cov*cov)\n",
    "        groundTruth = -0.5*np.log(np.linalg.det(np.array(Gaussian_cov2)))\n",
    "        GT2.append(groundTruth)\n",
    "\n",
    "\n",
    "        MI_knn0 = MI_Unsuperwise(x, MI_knn)\n",
    "        print(MI_knn0)\n",
    "        index = np.ma.array(np.arange(MI_knn0.shape[0]), mask=False)\n",
    "        print(MMI(MI_knn0, index, printAtDepth=-1))\n",
    "        KNN.append(MMI(MI_knn0, index, printAtDepth=-1))\n",
    "        #KNN.append(np.mean(MI_knn0))\n",
    "        \n",
    "        MI_MINE2 = MI_MINE(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(COV2, KNN, c='b', label='KNN')\n",
    "#ax.scatter(COV2, LinReg2, c='r', label='Regressor')\n",
    "ax.scatter(COV2, GT2, c='g', label='Ground Truth')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "COV22 = np.log(np.ones(len(COV2)) - COV2)\n",
    "ax2.scatter(COV22, KNN, c='b', label='KNN')\n",
    "#ax2.scatter(COV22, LinReg2, c='r', label='Regressor')\n",
    "ax2.scatter(COV22, GT2, c='g', label='Ground Truth')\n",
    "\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
